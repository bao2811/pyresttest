================================================================================
HÆ¯á»šNG DáºªN Sá»¬ Dá»¤NG NÃ‚NG CAO PYRESTTEST
TÃ€I LIá»†U Ká»¸ THUáº¬T: CÆ  CHáº¾ HOáº T Äá»˜NG VÃ€ Sá»¬ Dá»¤NG PROGRAMMATIC API
================================================================================

NgÃ y: 12/12/2025
TÃ¡c giáº£: bao2811
Má»¥c Ä‘Ã­ch: Giáº£i thÃ­ch chi tiáº¿t cÃ¡ch hoáº¡t Ä‘á»™ng, thÆ° viá»‡n/hÃ m Ä‘Æ°á»£c sá»­ dá»¥ng, vÃ  cÃ¡ch 
          táº¡o script Python Ä‘á»ƒ Ä‘á»c YAML config tÃ¹y chá»‰nh thay vÃ¬ cháº¡y qua CLI.

Má»¤C Lá»¤C
1. Tá»•ng quan cÃ¡c nÃ¢ng cáº¥p Ä‘Ã£ triá»ƒn khai
2. Chi tiáº¿t ká»¹ thuáº­t tá»«ng module
   2.1 Retry Module (pyresttest/retry.py)
   2.2 Performance Sync (pyresttest/performance.py)
   2.3 Performance Async (pyresttest/performance_async.py)
   2.4 Parallel Execution (pyresttest/resttest.py)
3. ThÆ° viá»‡n vÃ  Dependencies
4. CÃ¡ch PyRestTest Ä‘á»c vÃ  xá»­ lÃ½ YAML
5. Sá»­ dá»¥ng Programmatic API (táº¡o script.py riÃªng)
   5.1 Ká»‹ch báº£n 1: Cháº¡y test Ä‘Æ¡n giáº£n tá»« YAML
   5.2 Ká»‹ch báº£n 2: Cháº¡y vá»›i Retry Config
   5.3 Ká»‹ch báº£n 3: Cháº¡y Performance Test vá»›i Concurrency
   5.4 Ká»‹ch báº£n 4: Cháº¡y nhiá»u file YAML song song
   5.5 Ká»‹ch báº£n 5: Äá»c config tá»« JSON vÃ  cháº¡y
6. Auto-Runner Framework
7. Luá»“ng xá»­ lÃ½ hoÃ n chá»‰nh (tá»« YAML â†’ Result)
8. Best Practices vÃ  Tips

================================================================================
1. Tá»”NG QUAN CÃC NÃ‚NG Cáº¤P ÄÃƒ TRIá»‚N KHAI
================================================================================

GIAI ÄOáº N 1 (GÄ1): Performance & Async
â”œâ”€â”€ pyresttest/performance.py          â†’ Benchmark Ä‘á»“ng bá»™ (sync)
â””â”€â”€ pyresttest/performance_async.py    â†’ Benchmark báº¥t Ä‘á»“ng bá»™ (async)

GIAI ÄOáº N 2 (GÄ2): Retry, Concurrency, Programmatic API
â”œâ”€â”€ pyresttest/retry.py                â†’ Retry logic vá»›i exponential backoff
â”œâ”€â”€ TÃ­ch há»£p vÃ o performance.py        â†’ ThÃªm retry cho benchmark sync
â”œâ”€â”€ TÃ­ch há»£p vÃ o performance_async.py  â†’ ThÃªm retry cho benchmark async
â”œâ”€â”€ TÃ­ch há»£p vÃ o resttest.py           â†’ CLI flags vÃ  parallel execution
â”œâ”€â”€ examples/programmatic_usage.py     â†’ 8 vÃ­ dá»¥ sá»­ dá»¥ng API Python
â””â”€â”€ examples/auto_runner.py            â†’ Auto-runner vá»›i JSON config

NÃ‚NG Cáº¤P Bá»” SUNG: Parallel File Execution
â””â”€â”€ pyresttest/resttest.py             â†’ Cháº¡y nhiá»u file YAML song song vá»›i ProcessPoolExecutor

================================================================================
2. CHI TIáº¾T Ká»¸ THUáº¬T Tá»ªNG MODULE
================================================================================

2.1 RETRY MODULE (pyresttest/retry.py)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â–¸ Má»¤C ÄÃCH
  - Tá»± Ä‘á»™ng retry request khi gáº·p lá»—i táº¡m thá»i (5xx, timeout, connection error)
  - Sá»­ dá»¥ng exponential backoff Ä‘á»ƒ trÃ¡nh lÃ m quÃ¡ táº£i server

â–¸ Cáº¤U TRÃšC CHÃNH

class RetryConfig:
    """Cáº¥u hÃ¬nh retry"""
    Thuá»™c tÃ­nh:
    - max_retries: int          # Sá»‘ láº§n retry tá»‘i Ä‘a (máº·c Ä‘á»‹nh: 0)
    - backoff_base: float       # Thá»i gian chá» cÆ¡ báº£n (máº·c Ä‘á»‹nh: 0.5s)
    - backoff_max: float        # Thá»i gian chá» tá»‘i Ä‘a (máº·c Ä‘á»‹nh: 30s)
    - retryable_statuses: set   # HTTP codes cÃ³ thá»ƒ retry (máº·c Ä‘á»‹nh: {500,502,503,504})

â–¸ HÃ€M QUAN TRá»ŒNG

1. should_retry(status_code, exception)
   - Quyáº¿t Ä‘á»‹nh cÃ³ nÃªn retry hay khÃ´ng
   - Retry khi:
     â€¢ HTTP 5xx (500, 502, 503, 504)
     â€¢ Connection error (ConnectionError, Timeout)
     â€¢ Socket error, DNS resolution failed
   - KHÃ”NG retry khi:
     â€¢ HTTP 2xx, 3xx (thÃ nh cÃ´ng)
     â€¢ HTTP 4xx (lá»—i client, retry vÃ´ Ã­ch)

2. calculate_delay(attempt, backoff_base, backoff_max)
   - TÃ­nh thá»i gian chá» trÆ°á»›c khi retry
   - CÃ´ng thá»©c: delay = min(backoff_base * (2^attempt), backoff_max)
   - VÃ­ dá»¥: backoff_base=0.5, backoff_max=30
     â€¢ Attempt 0: 0.5s
     â€¢ Attempt 1: 1s
     â€¢ Attempt 2: 2s
     â€¢ Attempt 3: 4s
     â€¢ Attempt 4: 8s
     â€¢ Attempt 5: 16s
     â€¢ Attempt 6: 30s (Ä‘Ã£ Ä‘áº¡t max)

3. retry_sync(fn, retry_config, *args, **kwargs)
   - Wrapper cho hÃ m Ä‘á»“ng bá»™ (sync)
   - Tá»± Ä‘á»™ng retry khi should_retry() = True
   - Sá»­ dá»¥ng time.sleep() Ä‘á»ƒ chá» giá»¯a cÃ¡c láº§n retry
   - Tráº£ vá»: (result, retry_count)

4. retry_async(coro_fn, retry_config, *args, **kwargs)
   - Wrapper cho coroutine (async)
   - Tá»± Ä‘á»™ng retry khi should_retry() = True
   - Sá»­ dá»¥ng asyncio.sleep() Ä‘á»ƒ chá» (khÃ´ng cháº·n event loop)
   - Tráº£ vá»: (result, retry_count)

â–¸ CÃCH HOáº T Äá»˜NG (Pseudocode)

retry_sync/async:
    for attempt in range(max_retries + 1):
        try:
            result = execute_function()
            return (result, attempt)
        except Exception as e:
            if should_retry(status_code, e) and attempt < max_retries:
                delay = calculate_delay(attempt, backoff_base, backoff_max)
                sleep(delay)
                continue
            else:
                raise

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2.2 PERFORMANCE SYNC (pyresttest/performance.py)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â–¸ Má»¤C ÄÃCH
  - Benchmark endpoints vá»›i requests Ä‘á»“ng bá»™
  - Thu tháº­p metrics: min/max/avg response time, pass/fail count
  - Há»— trá»£ concurrency vá»›i ThreadPoolExecutor

â–¸ THÃ€NH PHáº¦N CHÃNH

1. BenchmarkConfig
   - warmup_runs: int         # Sá»‘ request khá»Ÿi Ä‘á»™ng (khÃ´ng tÃ­nh vÃ o káº¿t quáº£)
   - repeat: int              # Sá»‘ láº§n láº·p chÃ­nh
   - concurrency: int         # Sá»‘ request Ä‘á»“ng thá»i
   - timeout: float           # Timeout cho má»—i request
   - threshold_ms: float      # NgÆ°á»¡ng thá»i gian cháº¥p nháº­n Ä‘Æ°á»£c

2. run_benchmark_sync(test, benchmark_config, retry_config=None)
   - Cháº¡y benchmark vá»›i requests.Session
   - Sá»­ dá»¥ng ThreadPoolExecutor Ä‘á»ƒ kiá»ƒm soÃ¡t concurrency
   - TÃ­ch há»£p retry_sync() náº¿u retry_config Ä‘Æ°á»£c cung cáº¥p
   - Thu tháº­p thá»‘ng kÃª: response times, retry counts

â–¸ LUá»’NG HOáº T Äá»˜NG

1. Táº¡o requests.Session (connection pooling)
2. Warmup phase: cháº¡y warmup_runs request (bá» qua káº¿t quáº£)
3. Benchmark phase:
   - Táº¡o ThreadPoolExecutor(max_workers=concurrency)
   - Submit repeat tasks vÃ o pool
   - Má»—i task:
     â€¢ Gá»i retry_sync(make_request) náº¿u cÃ³ retry_config
     â€¢ Hoáº·c gá»i make_request() trá»±c tiáº¿p
     â€¢ Ghi láº¡i response time vÃ  káº¿t quáº£
   - Chá» táº¥t cáº£ tasks hoÃ n thÃ nh
4. TÃ­nh toÃ¡n metrics:
   - min/max/avg response time
   - total requests, passed, failed
   - total/avg retries
   - threshold violations

â–¸ CODE SNIPPET

from concurrent.futures import ThreadPoolExecutor
import requests

session = requests.Session()
with ThreadPoolExecutor(max_workers=concurrency) as executor:
    futures = []
    for i in range(repeat):
        future = executor.submit(execute_single_request, test, retry_config)
        futures.append(future)
    
    for future in as_completed(futures):
        result, retry_count = future.result()
        # Ghi nháº­n metrics

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2.3 PERFORMANCE ASYNC (pyresttest/performance_async.py)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â–¸ Má»¤C ÄÃCH
  - Benchmark vá»›i HTTP async (aiohttp) Ä‘á»ƒ tÄƒng throughput
  - KhÃ´ng cháº·n I/O, phÃ¹ há»£p vá»›i workload nhiá»u káº¿t ná»‘i

â–¸ THÃ€NH PHáº¦N CHÃNH

1. run_benchmark_async(test, benchmark_config, retry_config=None)
   - Sá»­ dá»¥ng aiohttp.ClientSession
   - Kiá»ƒm soÃ¡t concurrency vá»›i asyncio.Semaphore
   - TÃ­ch há»£p retry_async() cho má»—i request

â–¸ LUá»’NG HOáº T Äá»˜NG

1. Táº¡o aiohttp.ClientSession
2. Táº¡o asyncio.Semaphore(concurrency)
3. Warmup phase (async)
4. Benchmark phase:
   - Táº¡o danh sÃ¡ch coroutines
   - Má»—i coroutine:
     â€¢ Acquire semaphore (chá» náº¿u Ä‘Ã£ Ä‘áº¡t giá»›i háº¡n)
     â€¢ Gá»i retry_async(make_async_request)
     â€¢ Release semaphore
   - Cháº¡y asyncio.gather(*coroutines)
5. TÃ­nh toÃ¡n metrics tÆ°Æ¡ng tá»± sync

â–¸ CODE SNIPPET

import aiohttp
import asyncio

async def run_benchmark_async(test, config, retry_config):
    semaphore = asyncio.Semaphore(config.concurrency)
    
    async with aiohttp.ClientSession() as session:
        tasks = []
        for i in range(config.repeat):
            task = execute_with_semaphore(session, test, semaphore, retry_config)
            tasks.append(task)
        
        results = await asyncio.gather(*tasks)
    
    # TÃ­nh metrics tá»« results

async def execute_with_semaphore(session, test, semaphore, retry_config):
    async with semaphore:  # Giá»›i háº¡n concurrency
        result, retries = await retry_async(make_request, retry_config, session, test)
        return result, retries

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2.4 PARALLEL EXECUTION (pyresttest/resttest.py)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â–¸ Má»¤C ÄÃCH
  - Cháº¡y nhiá»u file YAML test song song (multi-process)
  - Giáº£m tá»•ng thá»i gian cháº¡y test suite lá»›n

â–¸ THÃ€NH PHáº¦N CHÃNH

1. execute_tests_with_args(args)
   - HÃ m Ä‘Æ°á»£c trÃ­ch xuáº¥t tá»« main()
   - Cháº¡y tests tá»« má»™t file YAML
   - Tráº£ vá» sá»‘ lÆ°á»£ng failures (thay vÃ¬ sys.exit)

2. _worker_execute_single_file(args_base, test_file)
   - Worker function cho ProcessPoolExecutor
   - Nháº­n args cÆ¡ báº£n + Ä‘Æ°á»ng dáº«n file
   - Gá»i execute_tests_with_args()
   - Tráº£ vá»: (test_file, failures, error_message)

3. execute_multiple_files(args_base, test_files, workers)
   - Orchestrator cho parallel execution
   - Sá»­ dá»¥ng ProcessPoolExecutor(max_workers=workers)
   - Submit má»—i file vÃ o process pool
   - Gom káº¿t quáº£ vÃ  tÃ­nh tá»•ng failures

â–¸ LUá»’NG HOáº T Äá»˜NG

CLI: pyresttest URL --tests "examples/*.yaml" --workers 4

1. Parse CLI args â†’ láº¥y test_files (glob expansion)
2. Náº¿u workers > 1 vÃ  cÃ³ nhiá»u files:
   - Gá»i execute_multiple_files()
   - Táº¡o ProcessPoolExecutor(max_workers=workers)
   - Submit má»—i file vÃ o pool
   - Má»—i worker process:
     â€¢ Cháº¡y execute_tests_with_args() vá»›i file Ä‘Ã³
     â€¢ Tráº£ vá» káº¿t quáº£
   - Main process nháº­n káº¿t quáº£, tÃ­nh tá»•ng failures
3. Náº¿u workers = 1 hoáº·c chá»‰ 1 file:
   - Cháº¡y tuáº§n tá»± execute_tests_with_args()

â–¸ CODE SNIPPET

from concurrent.futures import ProcessPoolExecutor, as_completed
import glob

test_files = []
for pattern in args.tests.split(','):
    test_files.extend(glob.glob(pattern.strip()))

with ProcessPoolExecutor(max_workers=workers) as executor:
    futures = {
        executor.submit(_worker_execute_single_file, args, f): f 
        for f in test_files
    }
    
    total_failures = 0
    for future in as_completed(futures):
        filename, failures, error = future.result()
        total_failures += failures
        print(f"File {filename}: {failures} failures")

return total_failures

================================================================================
3. THÆ¯ VIá»†N VÃ€ DEPENDENCIES
================================================================================

â–¸ CORE DEPENDENCIES (Built-in Python)
â”œâ”€â”€ time                    â†’ sleep() cho retry sync
â”œâ”€â”€ asyncio                 â†’ async/await, sleep() cho retry async
â”œâ”€â”€ concurrent.futures      â†’ ThreadPoolExecutor (sync concurrency)
â”‚                            â†’ ProcessPoolExecutor (parallel files)
â”œâ”€â”€ glob                    â†’ Má»Ÿ rá»™ng wildcard patterns (*.yaml)
â”œâ”€â”€ optparse                â†’ Parse CLI arguments
â””â”€â”€ json                    â†’ Äá»c JSON config cho auto-runner

â–¸ EXTERNAL DEPENDENCIES
â”œâ”€â”€ requests                â†’ HTTP client sync (performance.py)
â”œâ”€â”€ aiohttp                 â†’ HTTP client async (performance_async.py)
â”œâ”€â”€ pyyaml                  â†’ Parse YAML test files
â””â”€â”€ pycurl                  â†’ HTTP client gá»‘c (compatibility)

â–¸ OPTIONAL DEPENDENCIES
â””â”€â”€ aiohttp                 â†’ Chá»‰ cáº§n khi dÃ¹ng async mode

â–¸ PHÃ‚N Bá»” Sá»¬ Dá»¤NG THÆ¯ VIá»†N

Module                      | ThÆ° viá»‡n chÃ­nh
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
retry.py                    | time, asyncio
performance.py              | requests, ThreadPoolExecutor, retry
performance_async.py        | aiohttp, asyncio.Semaphore, retry
resttest.py (parallel)      | ProcessPoolExecutor, glob
resttest.py (core)          | pycurl, requests, pyyaml
auto_runner.py              | json, argparse

â–¸ PYTHON VERSION SUPPORT
- Python 2.6, 2.7: concurrent.futures qua backport
- Python 3.3+: concurrent.futures built-in
- Async features: Python 3.5+ (async/await syntax)

================================================================================
4. CÃCH PYRESTTEST Äá»ŒC VÃ€ Xá»¬ LÃ YAML
================================================================================

â–¸ Äá»ŠNH Dáº NG YAML CÆ  Báº¢N

---
- config:
    - testset: "My API Tests"

- test:
    - name: "Get user"
    - url: "/users/1"
    - method: "GET"
    - expected_status: [200]
    - validators:
        - compare: {jsonpath_mini: "id", expected: 1}

- test:
    - name: "Create user"
    - url: "/users"
    - method: "POST"
    - headers: {Content-Type: "application/json"}
    - body: '{"name": "John", "email": "john@example.com"}'
    - expected_status: [201]

â–¸ YAML Vá»šI PERFORMANCE (BENCHMARK)

- benchmark:
    - name: "Load test endpoint"
    - url: "/api/data"
    - method: "GET"
    - warmup_runs: 10
    - repeat: 100
    - concurrency: 10
    - mode: "sync"  # hoáº·c "async"
    - timeout: 30
    - threshold_ms: 500

â–¸ LUá»’NG PARSE YAML

1. Äá»c file YAML â†’ yaml.safe_load()
2. Parse thÃ nh list of test/config/benchmark objects
3. Vá»›i má»—i object:
   - Náº¿u lÃ  'config': LÆ°u cáº¥u hÃ¬nh global
   - Náº¿u lÃ  'test': Táº¡o Test object
   - Náº¿u lÃ  'benchmark': Táº¡o Benchmark object
4. Thá»±c thi tá»«ng test/benchmark theo thá»© tá»±

â–¸ CODE TRONG resttest.py (simplified)

import yaml

def parse_yaml_test_file(file_path):
    with open(file_path, 'r') as f:
        yaml_data = yaml.safe_load(f)
    
    tests = []
    benchmarks = []
    config = {}
    
    for item in yaml_data:
        if 'config' in item:
            config.update(item['config'])
        elif 'test' in item:
            test = parse_test(item['test'])
            tests.append(test)
        elif 'benchmark' in item:
            benchmark = parse_benchmark(item['benchmark'])
            benchmarks.append(benchmark)
    
    return tests, benchmarks, config

â–¸ TRÃCH XUáº¤T THÃ”NG TIN Tá»ª YAML

Test object sáº½ cÃ³:
- name: str
- url: str
- method: str (GET/POST/PUT/DELETE/PATCH)
- headers: dict
- body: str hoáº·c template
- expected_status: list of int
- validators: list of Validator objects
- extractors: list of Extractor objects

Benchmark object sáº½ cÃ³:
- Táº¥t cáº£ thuá»™c tÃ­nh cá»§a Test
- warmup_runs: int
- repeat: int
- concurrency: int
- mode: "sync" | "async"
- timeout: float
- threshold_ms: float

================================================================================
5. Sá»¬ Dá»¤NG PROGRAMMATIC API (Táº O SCRIPT.PY RIÃŠNG)
================================================================================

Thay vÃ¬ cháº¡y CLI: `pyresttest URL test.yaml`
Báº¡n cÃ³ thá»ƒ viáº¿t script Python Ä‘á»ƒ:
- Äá»c YAML tÃ¹y chá»‰nh
- Cáº¥u hÃ¬nh retry/concurrency Ä‘á»™ng
- Xá»­ lÃ½ káº¿t quáº£ theo logic riÃªng
- TÃ­ch há»£p vÃ o CI/CD pipeline phá»©c táº¡p

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
5.1 Ká»ŠCH Báº¢N 1: Cháº¡y test Ä‘Æ¡n giáº£n tá»« YAML
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â–¸ FILE: my_test_runner.py

#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Script tÃ¹y chá»‰nh Ä‘á»ƒ cháº¡y PyRestTest tá»« YAML
"""

import sys
import os

# ThÃªm pyresttest vÃ o path (náº¿u chÆ°a cÃ i Ä‘áº·t)
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'pyresttest'))

from pyresttest import resttest
from pyresttest.binding import Context

def run_tests_from_yaml(base_url, yaml_file):
    """
    Cháº¡y tests tá»« file YAML
    
    Args:
        base_url: URL gá»‘c (vd: https://api.example.com)
        yaml_file: ÄÆ°á»ng dáº«n Ä‘áº¿n file YAML
    
    Returns:
        int: Sá»‘ lÆ°á»£ng test tháº¥t báº¡i
    """
    # Táº¡o context (mÃ´i trÆ°á»ng cháº¡y test)
    context = Context()
    
    # Parse YAML file
    tests = resttest.read_test_file(yaml_file)
    
    # Cáº¥u hÃ¬nh
    test_config = resttest.TestConfig()
    test_config.print_bodies = False
    test_config.print_headers = False
    test_config.interactive = False
    
    # Cháº¡y tests
    failures = 0
    for test in tests:
        mytest = test.realize(context)
        result = resttest.run_test(mytest, test_config, context, base_url)
        
        if not result.passed:
            failures += 1
            print(f"âŒ FAILED: {test.name}")
        else:
            print(f"âœ… PASSED: {test.name}")
    
    return failures

if __name__ == "__main__":
    base_url = "https://jsonplaceholder.typicode.com"
    yaml_file = "examples/miniapp-test.yaml"
    
    failures = run_tests_from_yaml(base_url, yaml_file)
    
    print(f"\nTá»•ng káº¿t: {failures} test(s) tháº¥t báº¡i")
    sys.exit(failures)

â–¸ CHáº Y

python my_test_runner.py

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
5.2 Ká»ŠCH Báº¢N 2: Cháº¡y vá»›i Retry Config
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â–¸ FILE: my_test_runner_with_retry.py

#!/usr/bin/env python
# -*- coding: utf-8 -*-

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'pyresttest'))

from pyresttest import resttest
from pyresttest.retry import RetryConfig
from pyresttest.binding import Context

def run_tests_with_retry(base_url, yaml_file, max_retries=3):
    """
    Cháº¡y tests vá»›i retry configuration
    """
    # Táº¡o retry config
    retry_config = RetryConfig(
        max_retries=max_retries,
        backoff_base=0.5,
        backoff_max=30.0
    )
    
    context = Context()
    tests = resttest.read_test_file(yaml_file)
    
    test_config = resttest.TestConfig()
    test_config.retry_config = retry_config  # GÃ¡n retry config
    
    failures = 0
    total_retries = 0
    
    for test in tests:
        mytest = test.realize(context)
        
        # Run test (ná»™i bá»™ sáº½ dÃ¹ng retry_config)
        result = resttest.run_test(mytest, test_config, context, base_url)
        
        if hasattr(result, 'retry_count'):
            total_retries += result.retry_count
        
        if not result.passed:
            failures += 1
            print(f"âŒ FAILED: {test.name} (retries: {getattr(result, 'retry_count', 0)})")
        else:
            print(f"âœ… PASSED: {test.name} (retries: {getattr(result, 'retry_count', 0)})")
    
    print(f"\nTá»•ng retries: {total_retries}")
    print(f"Tá»•ng failures: {failures}")
    
    return failures

if __name__ == "__main__":
    base_url = "https://jsonplaceholder.typicode.com"
    yaml_file = "examples/miniapp-test.yaml"
    
    failures = run_tests_with_retry(base_url, yaml_file, max_retries=3)
    sys.exit(failures)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
5.3 Ká»ŠCH Báº¢N 3: Cháº¡y Performance Test vá»›i Concurrency
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â–¸ FILE: my_benchmark_runner.py

#!/usr/bin/env python
# -*- coding: utf-8 -*-

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'pyresttest'))

from pyresttest import resttest
from pyresttest.performance import BenchmarkConfig, run_benchmark_sync
from pyresttest.retry import RetryConfig
from pyresttest.binding import Context

def run_benchmark(base_url, yaml_file, concurrency=10, repeat=100):
    """
    Cháº¡y performance benchmark vá»›i concurrency control
    """
    # Cáº¥u hÃ¬nh benchmark
    benchmark_config = BenchmarkConfig(
        warmup_runs=10,
        repeat=repeat,
        concurrency=concurrency,
        timeout=30.0,
        threshold_ms=500.0
    )
    
    # Cáº¥u hÃ¬nh retry
    retry_config = RetryConfig(
        max_retries=2,
        backoff_base=0.5,
        backoff_max=10.0
    )
    
    context = Context()
    tests = resttest.read_test_file(yaml_file)
    
    for test in tests:
        mytest = test.realize(context)
        
        print(f"\nğŸš€ Running benchmark: {test.name}")
        print(f"   Concurrency: {concurrency}, Repeat: {repeat}")
        
        # Cháº¡y benchmark
        result = run_benchmark_sync(
            mytest, 
            benchmark_config, 
            retry_config=retry_config,
            base_url=base_url
        )
        
        # In káº¿t quáº£
        print(f"\nğŸ“Š Results:")
        print(f"   Total requests: {result.total_requests}")
        print(f"   Passed: {result.passed}")
        print(f"   Failed: {result.failed}")
        print(f"   Min time: {result.min_time:.2f}ms")
        print(f"   Max time: {result.max_time:.2f}ms")
        print(f"   Avg time: {result.avg_time:.2f}ms")
        print(f"   Total retries: {result.total_retries}")
        print(f"   Avg retries: {result.avg_retries:.2f}")

if __name__ == "__main__":
    base_url = "https://jsonplaceholder.typicode.com"
    yaml_file = "examples/miniapp-benchmark.yaml"
    
    run_benchmark(base_url, yaml_file, concurrency=20, repeat=200)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
5.4 Ká»ŠCH Báº¢N 4: Cháº¡y nhiá»u file YAML song song
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â–¸ FILE: my_parallel_runner.py

#!/usr/bin/env python
# -*- coding: utf-8 -*-

import sys
import os
import glob
from concurrent.futures import ProcessPoolExecutor, as_completed

sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'pyresttest'))

from pyresttest import resttest
from pyresttest.retry import RetryConfig
from pyresttest.binding import Context

def run_single_file(base_url, yaml_file, retry_config):
    """
    Worker function: cháº¡y má»™t file YAML
    """
    try:
        context = Context()
        tests = resttest.read_test_file(yaml_file)
        
        test_config = resttest.TestConfig()
        test_config.retry_config = retry_config
        
        failures = 0
        for test in tests:
            mytest = test.realize(context)
            result = resttest.run_test(mytest, test_config, context, base_url)
            
            if not result.passed:
                failures += 1
        
        return (yaml_file, failures, None)
    
    except Exception as e:
        return (yaml_file, -1, str(e))

def run_parallel_tests(base_url, pattern, workers=4, max_retries=3):
    """
    Cháº¡y nhiá»u file YAML song song vá»›i ProcessPoolExecutor
    
    Args:
        base_url: URL gá»‘c
        pattern: Glob pattern (vd: "examples/*.yaml")
        workers: Sá»‘ worker processes
        max_retries: Sá»‘ láº§n retry tá»‘i Ä‘a
    """
    # TÃ¬m táº¥t cáº£ files khá»›p pattern
    yaml_files = glob.glob(pattern)
    
    if not yaml_files:
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file nÃ o khá»›p: {pattern}")
        return 1
    
    print(f"ğŸ“ TÃ¬m tháº¥y {len(yaml_files)} file(s)")
    print(f"âš™ï¸  Cháº¡y vá»›i {workers} worker(s)\n")
    
    # Cáº¥u hÃ¬nh retry
    retry_config = RetryConfig(
        max_retries=max_retries,
        backoff_base=0.5,
        backoff_max=30.0
    )
    
    # Cháº¡y song song
    total_failures = 0
    
    with ProcessPoolExecutor(max_workers=workers) as executor:
        # Submit táº¥t cáº£ files
        futures = {
            executor.submit(run_single_file, base_url, f, retry_config): f
            for f in yaml_files
        }
        
        # Nháº­n káº¿t quáº£ khi hoÃ n thÃ nh
        for future in as_completed(futures):
            filename = futures[future]
            
            try:
                file_path, failures, error = future.result()
                
                if error:
                    print(f"âŒ {os.path.basename(file_path)}: ERROR - {error}")
                    total_failures += 1
                elif failures > 0:
                    print(f"âš ï¸  {os.path.basename(file_path)}: {failures} failure(s)")
                    total_failures += failures
                else:
                    print(f"âœ… {os.path.basename(file_path)}: All tests passed")
            
            except Exception as e:
                print(f"âŒ {os.path.basename(filename)}: Exception - {e}")
                total_failures += 1
    
    print(f"\nğŸ“Š Tá»•ng káº¿t: {total_failures} failure(s) across all files")
    return total_failures

if __name__ == "__main__":
    base_url = "https://jsonplaceholder.typicode.com"
    pattern = "examples/*.yaml"
    workers = 4
    
    failures = run_parallel_tests(base_url, pattern, workers=workers, max_retries=3)
    sys.exit(min(failures, 1))

â–¸ CHáº Y

python my_parallel_runner.py

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
5.5 Ká»ŠCH Báº¢N 5: Äá»c config tá»« JSON vÃ  cháº¡y (Auto-Runner Pattern)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â–¸ FILE: my_config.json

{
  "project_name": "My API Test Suite",
  "base_url": "https://jsonplaceholder.typicode.com",
  "global_settings": {
    "retry": {
      "max_retries": 3,
      "backoff_base": 0.5,
      "backoff_max": 30
    },
    "concurrency": {
      "max_concurrent": 10
    }
  },
  "environments": {
    "dev": {
      "base_url": "http://localhost:8000"
    },
    "staging": {
      "base_url": "https://staging-api.example.com"
    },
    "prod": {
      "base_url": "https://api.example.com"
    }
  },
  "test_suites": [
    {
      "name": "Smoke Tests",
      "enabled": true,
      "files": [
        "examples/miniapp-test.yaml",
        "examples/github_api_smoketest.yaml"
      ]
    },
    {
      "name": "Load Tests",
      "enabled": false,
      "files": [
        "examples/miniapp-benchmark.yaml"
      ]
    }
  ]
}

â–¸ FILE: my_json_runner.py

#!/usr/bin/env python
# -*- coding: utf-8 -*-

import sys
import os
import json

sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'pyresttest'))

from pyresttest import resttest
from pyresttest.retry import RetryConfig
from pyresttest.binding import Context

def load_config(config_file):
    """Äá»c JSON config"""
    with open(config_file, 'r') as f:
        return json.load(f)

def run_from_json_config(config_file, environment='prod'):
    """
    Cháº¡y tests theo cáº¥u hÃ¬nh JSON
    
    Args:
        config_file: ÄÆ°á»ng dáº«n Ä‘áº¿n file JSON config
        environment: MÃ´i trÆ°á»ng (dev/staging/prod)
    """
    # Äá»c config
    config = load_config(config_file)
    
    # Láº¥y base URL theo environment
    if environment in config.get('environments', {}):
        base_url = config['environments'][environment]['base_url']
    else:
        base_url = config.get('base_url', '')
    
    print(f"ğŸŒ Environment: {environment}")
    print(f"ğŸ”— Base URL: {base_url}\n")
    
    # Láº¥y global settings
    global_settings = config.get('global_settings', {})
    retry_settings = global_settings.get('retry', {})
    concurrency_settings = global_settings.get('concurrency', {})
    
    # Táº¡o retry config
    retry_config = RetryConfig(
        max_retries=retry_settings.get('max_retries', 0),
        backoff_base=retry_settings.get('backoff_base', 0.5),
        backoff_max=retry_settings.get('backoff_max', 30.0)
    )
    
    # Cháº¡y test suites
    total_failures = 0
    
    for suite in config.get('test_suites', []):
        if not suite.get('enabled', True):
            print(f"â­ï¸  Skipping suite: {suite['name']} (disabled)\n")
            continue
        
        print(f"ğŸ“¦ Running suite: {suite['name']}")
        
        for yaml_file in suite.get('files', []):
            print(f"  ğŸ“„ {yaml_file}")
            
            try:
                context = Context()
                tests = resttest.read_test_file(yaml_file)
                
                test_config = resttest.TestConfig()
                test_config.retry_config = retry_config
                
                for test in tests:
                    mytest = test.realize(context)
                    result = resttest.run_test(mytest, test_config, context, base_url)
                    
                    if not result.passed:
                        total_failures += 1
                        print(f"    âŒ {test.name}")
                    else:
                        print(f"    âœ… {test.name}")
            
            except Exception as e:
                print(f"    âŒ Error: {e}")
                total_failures += 1
        
        print()
    
    print(f"ğŸ“Š Tá»•ng káº¿t: {total_failures} failure(s)")
    return total_failures

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='Run tests from JSON config')
    parser.add_argument('--config', default='my_config.json', help='JSON config file')
    parser.add_argument('--env', default='prod', help='Environment (dev/staging/prod)')
    
    args = parser.parse_args()
    
    failures = run_from_json_config(args.config, args.env)
    sys.exit(min(failures, 1))

â–¸ CHáº Y

python my_json_runner.py --config my_config.json --env staging

================================================================================
6. AUTO-RUNNER FRAMEWORK
================================================================================

PyRestTest Ä‘Ã£ cÃ³ sáºµn auto-runner trong examples/auto_runner.py

â–¸ CÃCH Sá»¬ Dá»¤NG

1. Táº¡o file test_config.json (xem examples/test_config.json)
2. Cháº¡y:
   
   python examples/auto_runner.py --config examples/test_config.json --env dev

â–¸ TÃNH NÄ‚NG

- Äá»c cáº¥u hÃ¬nh tá»« JSON
- Há»— trá»£ nhiá»u mÃ´i trÆ°á»ng (dev/staging/prod)
- Global settings (retry, concurrency)
- Per-suite settings override
- Enable/disable suites
- Xuáº¥t bÃ¡o cÃ¡o káº¿t quáº£

â–¸ Cáº¤U TRÃšC JSON

{
  "project_name": "...",
  "base_url": "...",
  "global_settings": {
    "retry": {...},
    "concurrency": {...}
  },
  "environments": {
    "dev": {...},
    "staging": {...}
  },
  "test_suites": [
    {
      "name": "Suite 1",
      "enabled": true,
      "files": ["test1.yaml", "test2.yaml"],
      "settings": {
        "retry": {...}  // Override global
      }
    }
  ]
}

================================================================================
7. LUá»’NG Xá»¬ LÃ HOÃ€N CHá»ˆNH (Tá»ª YAML â†’ RESULT)
================================================================================

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Äá»ŒC YAML FILE                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ yaml.safe_load(file) â†’ list of dicts                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. PARSE TESTS/BENCHMARKS                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - Táº¡o Test objects tá»« YAML                                             â”‚
â”‚ - Táº¡o Benchmark objects tá»« YAML                                        â”‚
â”‚ - LÆ°u config global                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. REALIZE TEST (binding context)                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - Thay tháº¿ variables (${VAR})                                           â”‚
â”‚ - Apply templates                                                       â”‚
â”‚ - Táº¡o final Test object                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Táº O HTTP REQUEST                                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - Build URL: base_url + test.url                                       â”‚
â”‚ - Set method, headers, body                                             â”‚
â”‚ - Configure timeout                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. THá»°C THI REQUEST (vá»›i retry náº¿u cÃ³)                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ if retry_config:                                                        â”‚
â”‚     response, retries = retry_sync/async(make_request, retry_config)   â”‚
â”‚ else:                                                                   â”‚
â”‚     response = make_request()                                           â”‚
â”‚     retries = 0                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. Xá»¬ LÃ RESPONSE                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - Parse JSON/XML/Text                                                   â”‚
â”‚ - Extract data (extractors)                                            â”‚
â”‚ - Update context variables                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. VALIDATE RESPONSE                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - Check status code                                                     â”‚
â”‚ - Run validators (jsonpath, regex, compare, etc.)                      â”‚
â”‚ - TÃ­nh pass/fail                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 8. Táº O RESULT OBJECT                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TestResult:                                                             â”‚
â”‚   - passed: bool                                                        â”‚
â”‚   - failures: list                                                      â”‚
â”‚   - response_code: int                                                  â”‚
â”‚   - response_body: str                                                  â”‚
â”‚   - retry_count: int (náº¿u cÃ³ retry)                                     â”‚
â”‚   - response_time: float (ms)                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 9. GOM Káº¾T QUáº¢                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - Äáº¿m total tests, passed, failed                                      â”‚
â”‚ - Thu tháº­p metrics (náº¿u benchmark)                                     â”‚
â”‚ - In bÃ¡o cÃ¡o                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

================================================================================
8. BEST PRACTICES VÃ€ TIPS
================================================================================

â–¸ KHI NÃ€O DÃ™NG CLI, KHI NÃ€O DÃ™NG PROGRAMMATIC API?

â”œâ”€ CLI (pyresttest)
â”‚  â”œâ”€ Quick smoke tests
â”‚  â”œâ”€ CI/CD Ä‘Æ¡n giáº£n
â”‚  â””â”€ Cháº¡y thá»§ cÃ´ng, debug
â”‚
â””â”€ Programmatic API (script.py)
   â”œâ”€ Logic phá»©c táº¡p (conditional execution)
   â”œâ”€ TÃ­ch há»£p sÃ¢u vÃ o Python workflow
   â”œâ”€ Custom reporting
   â”œâ”€ Multi-environment orchestration
   â””â”€ Dynamic test generation

â–¸ RETRY CONFIGURATION TIPS

1. CI/CD: max_retries=2-3, backoff_base=0.5
   â†’ Giáº£m flakiness nhÆ°ng khÃ´ng lÃ m cháº­m quÃ¡ nhiá»u

2. Load test: max_retries=0-1
   â†’ Giá»¯ Ä‘áº·c tÃ­nh táº£i thá»±c táº¿

3. Monitoring: max_retries=3-5, backoff_max=60
   â†’ Æ¯u tiÃªn Ä‘á»™ tin cáº­y

â–¸ CONCURRENCY TIPS

1. Sync mode:
   - concurrency = 5-20: PhÃ¹ há»£p cho HTTP/1.1
   - concurrency > 50: CÃ¢n nháº¯c async mode

2. Async mode:
   - concurrency = 50-500: Táº­n dá»¥ng I/O khÃ´ng cháº·n
   - Cáº§n aiohttp installed

3. Parallel files:
   - workers = sá»‘ CPU cores (4-8)
   - KhÃ´ng nÃªn > sá»‘ files

â–¸ YAML ORGANIZATION

my-tests/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ dev.yaml       # Config cho dev
â”‚   â”œâ”€â”€ staging.yaml   # Config cho staging
â”‚   â””â”€â”€ prod.yaml      # Config cho prod
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ auth/
â”‚   â”‚   â”œâ”€â”€ login.yaml
â”‚   â”‚   â””â”€â”€ logout.yaml
â”‚   â”œâ”€â”€ users/
â”‚   â”‚   â”œâ”€â”€ create.yaml
â”‚   â”‚   â””â”€â”€ read.yaml
â”‚   â””â”€â”€ smoke.yaml
â””â”€â”€ benchmarks/
    â”œâ”€â”€ load-test.yaml
    â””â”€â”€ stress-test.yaml

â–¸ LOGGING & DEBUGGING

1. Báº­t verbose mode trong script:

   test_config.verbose = True
   test_config.print_bodies = True
   test_config.print_headers = True

2. Logging retry attempts:

   import logging
   logging.basicConfig(level=logging.DEBUG)
   # Sáº½ tháº¥y má»—i láº§n retry + delay

â–¸ ERROR HANDLING

try:
    failures = run_tests_from_yaml(base_url, yaml_file)
except FileNotFoundError:
    print(f"âŒ File not found: {yaml_file}")
    sys.exit(1)
except yaml.YAMLError as e:
    print(f"âŒ YAML parse error: {e}")
    sys.exit(1)
except Exception as e:
    print(f"âŒ Unexpected error: {e}")
    sys.exit(1)

â–¸ CI/CD INTEGRATION

# .github/workflows/api-tests.yml
- name: Run API Tests
  run: |
    python my_test_runner.py --config test_config.json --env staging
  
# Hoáº·c dÃ¹ng CLI
- name: Run API Tests (CLI)
  run: |
    pyresttest https://staging-api.example.com \
      --tests "tests/*.yaml" \
      --workers 4 \
      --max-retries 3 \
      --max-concurrency 10

================================================================================
Káº¾T LUáº¬N
================================================================================

TÃ i liá»‡u nÃ y Ä‘Ã£ trÃ¬nh bÃ y:

âœ… CÆ¡ cháº¿ hoáº¡t Ä‘á»™ng chi tiáº¿t cá»§a cÃ¡c module nÃ¢ng cáº¥p
   - Retry (exponential backoff, should_retry logic)
   - Performance Sync (ThreadPoolExecutor, requests.Session)
   - Performance Async (asyncio.Semaphore, aiohttp)
   - Parallel Execution (ProcessPoolExecutor, glob)

âœ… ThÆ° viá»‡n vÃ  dependencies sá»­ dá»¥ng
   - Built-in: time, asyncio, concurrent.futures, glob
   - External: requests, aiohttp, pyyaml

âœ… CÃ¡ch PyRestTest parse vÃ  xá»­ lÃ½ YAML
   - Cáº¥u trÃºc YAML: test/benchmark/config
   - Luá»“ng: YAML â†’ parse â†’ realize â†’ execute â†’ validate â†’ result

âœ… 5 ká»‹ch báº£n sá»­ dá»¥ng Programmatic API
   - Cháº¡y test Ä‘Æ¡n giáº£n
   - Cháº¡y vá»›i retry
   - Cháº¡y benchmark vá»›i concurrency
   - Cháº¡y song song nhiá»u files
   - Cháº¡y tá»« JSON config (auto-runner)

âœ… Best practices vÃ  tips
   - Khi nÃ o dÃ¹ng CLI vs Script
   - Retry/Concurrency configuration
   - YAML organization
   - CI/CD integration

Báº N CÃ“ THá»‚:
1. DÃ¹ng CLI cho quick tests: `pyresttest URL test.yaml --max-retries 3`
2. Viáº¿t script.py riÃªng Ä‘á»ƒ tÃ­ch há»£p sÃ¢u vÃ o workflow Python
3. DÃ¹ng auto-runner vá»›i JSON config cho multi-environment

Háº¾T
================================================================================
